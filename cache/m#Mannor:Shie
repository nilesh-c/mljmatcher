["Shie Mannor", ["Activity and Gait Recognition with Time-Delay Embeddings.", "Adaptive Timeout Policies for Fast Fine-Grained Power Management.", "Online Learning with Expert Advice and Finite-Horizon Constraints.", "User Model and Utility Based Power Management.", "Activity Recognition with Time-Delay Emobeddings.", "On identifying the causative network of an epidemic.", "Energy-efficient gear-shift LDPC decoders.", "Stochastic bandits with pathwise constraints.", "Adaptive bases for Q-learning.", "Regulation and efficiency in markets with friction.", "Regulation and double price mechanisms in markets with friction.", "Duality of ancillary services and intermittent suppliers.", "Large scale real-time bidding in the smart grid: A mean field framework.", "Risk sensitive robust support vector machines.", "Parametric regret in uncertain Markov decision processes.", "Arbitrarily modulated Markov decision processes.", "COLT 2012 - The 25th Annual Conference on Learning Theory, June 25-27, 2012, Edinburgh, Scotland", "Online Learning for Time Series Prediction.", "Opportunistic Strategies for Generalized No-Regret Problems.", "An Inequality for Nearly Log-Concave Distributions with Applications to Learning.", "Learning in the Limit with Adversarial Disturbances.", "Online Learning for Global Cost Functions.", "PAC Bounds for Multi-armed Bandit and Markov Decision Processes.", "Learning with Global Cost in Stochastic Environments.", "Strategies for Prediction Under Imperfect Monitoring.", "Reinforcement Learning for Average Reward Zero-Sum Games.", "Geometric Bounds for Generalization in Boosting.", "The Consistency of Greedy Algorithms for Classification.", "Approachability in unknown games: Online learning meets multi-objective optimization.", "Adaptive Strategies and Regret Minimization in Arbitrarily Varying Markov Environments.", "On-Line Learning with Imperfect Monitoring.", "Online Learning with Variable Stage Duration.", "Lower Bounds on the Sample Complexity of Exploration in the Multi-armed Bandit Problem.", "Online Learning with Constraints.", "Approachability, fast and slow.", "Principal Component Analysis with Contaminated Data: The High Dimensional Case.", "Robustness and Generalization.", "Sparse Online Greedy Support Vector Regression.", "Q-Cut - Dynamic Discovery of Sub-goals in Reinforcement Learning.", "Heterogeneous Stream Processing and Crowdsourcing for Urban Traffic Management.", "Combining a Gauss-Markov model and Gaussian process for traffic prediction in Dublin city center.", "Efficient Reinforcement Learning in Parameterized Models: Discrete Parameter Case.", "Regularized Fitted Q-Iteration: Application to Planning.", "Markov Decision Processes with Arbitrary Reward Processes.", "Non-Cooperative Design of Translucent Networks.", "A Relaxed Half-Stochastic Iterative Decoder for LDPC Codes.", "Lowering Error Floors Using Dithered Belief Propagation.", "A novel similarity measure for time series data with applications to gait and activity recognition.", "Tracking Forecast Memories in stochastic decoders.", "Stochastic Decoding of LDPC Codes over GF(q).", "Resource Allocation with Supply Adjustment in Distributed Computing Systems.", "Decoupling Exploration and Exploitation in Multi-Armed Bandits.", "Policy Gradients with Variance Related Risk Criteria.", "Robust Sparse Regression under Adversarial Corruption.", "Percentile optimization in uncertain Markov decision processes with application to efficient exploration.", "Learning Embedded Maps of Markov Processes.", "Bayes Meets Bellman: The Gaussian Process Approach to Temporal Difference Learning.", "Reinforcement learning with Gaussian processes.", "Action Elimination and Stopping Conditions for Reinforcement Learning.", "Reinforcement learning in the presence of rare events.", "Thompson Sampling for Complex Online Problems.", "Learning from Multiple Outlooks.", "Concept Drift Detection Through Resampling.", "Automatic basis function construction for approximate dynamic programming and reinforcement learning.", "Latent Bandits.", "Scaling Up Approximate Value Iteration with Options: Better Policies with Fewer Iterations.", "Time-Regularized Interrupting Options (TRIO).", "Dynamic abstraction in reinforcement learning via clustering.", "Lightning Does Not Strike Twice: Robust MDPs with Coupled Uncertainty.", "The cross entropy method for classification.", "The Cross Entropy Method for Fast Policy Search.", "Bias and variance in value function estimation.", "Mean-Variance Optimization in Markov Decision Processes.", "Temporal Difference Methods for the Variance of the Reward To Go.", "Scaling Up Robust MDPs using Function Approximation.", "Bundle Selling by Online Estimation of Valuation Functions.", "Piecewise-stationary bandit problems with side observations.", "Unimodal Bandits.", "Probabilistic Goal Markov Decision Processes.", "A state action frequency approach to throughput maximization over uncertain wireless channels.", "Asymptotics of Efficiency Loss in Competitive Market Mechanisms.", "A Lazy Approach to Online Learning with Constraints.", "Survey of Stochastic Computation on Factor Graphs.", "Model selection in markovian processes.", "Loop-Aware Memory Prefetching Using Code Block Working Sets.", "Detecting epidemics using highly noisy data.", "Reinforcement Learning-Based Load Shared Sequential Routing.", "Online Classification with Specificity Constraints.", "Committing Bandits.", "Regularized Policy Iteration.", "Online PCA for Contaminated Data.", "Robust Logistic Regression and Classification.", "The Perturbed Variation.", "Reinforcement Learning in Robust Markov Decision Processes.", "How hard is my MDP?\" The distribution-norm to the rescue\".", "Weak Learners and Improved Rates of Convergence in Boosting.", "The Steering Approach for Multi-Criteria Reinforcement Learning.", "From Bandits to Experts: On the Value of Side-Observations.", "Learning Multiple Models via Regularized Weighting.", "Robust Regression and Lasso.", "The Robustness-Performance Tradeoff in Markov Decision Processes.", "Distributionally Robust Markov Decision Processes.", "Concurrent Bandits and Cognitive Radio Networks.", "Sub-sampling for Multi-armed Bandits.", "Adaptive Bases for Reinforcement Learning.", "Activity Recognition with Mobile Phones.", "Heterogeneous Stream Processing and Crowdsourcing for Traffic Monitoring: Highlights.", "Network formation games with heterogeneous players and the internet structure.", "Network forensics: random infection vs spreading epidemic.", "Bidirectional interleavers for LDPC decoders using transmission gates.", "An Area-Efficient FPGA-Based Architecture for Fully-Parallel Stochastic LDPC Decoding.", "Joint Stochastic Decoding of LDPC Codes and Partial-Response Channels.", "Network Formation: Bilateral Contracting and Myopic Dynamics.", "Local Two-Stage Myopic Dynamics for Network Formation Games.", "Multi-agent learning for engineers.", "The Workshop Program at the Nineteenth National Conference on Artificial Intelligence.", "A Tutorial on the Cross-Entropy Method.", "Approximately optimal bidding policies for repeated first-price auctions.", "Basis Function Adaptation in Temporal Difference Reinforcement Learning.", "Nonstochastic Multi-Armed Bandits with Graph-Structured Feedback.", "Concurrent bandits and cognitive radio networks.", "Oracle-Based Robust Optimization via Online Learning.", "Distributed Robust Learning.", "Thompson Sampling for Learning Parameterized MDPs.", "Thompson Sampling for Complex Bandit Problems.", "Approachability in unknown games: Online learning meets multi-objective optimization.", "Localized epidemic detection in networks with overwhelming noise.", "Formation Games and the Internet Structure.", "Formation Games of Reliable Networks.", "Distinguishing Infections on Different Graph Topologies.", "Policy Gradients Beyond Expectations: Conditional Value-at-Risk.", "Variance Adjusted Actor Critic Algorithms.", "Implicit Temporal Differences.", "Scaling Up Robust MDPs by Reinforcement Learning.", "Robustness, Risk, and Regularization in Support Vector Machines", "Robust Regression and Lasso", "Learning from Multiple Outlooks", "Adaptive Bases for Reinforcement Learning", "Robustness and Generalization", "The Sample Complexity of Dictionary Learning", "Mean-Variance Optimization in Markov Decision Processes", "A Maximal Large Deviation Inequality for Sub-Gaussian Variables", "Robust approachability and regret minimization in games with partial monitoring", "From Bandits to Experts: On the Value of Side-Observations", "Bandits with an Edge", "Regulation, Volatility and Efficiency in Continuous-Time Markets", "Relaxed Half-Stochastic Belief Propagation", "Decoupling Exploration and Exploitation in Multi-Armed Bandits", "Clustered Bandits", "Lightning Does Not Strike Twice: Robust MDPs with Coupled Uncertainty", "How to sample if you must: on optimal functional sampling", "More Is Better: Large Scale Partially-supervised Sentiment Classification - Appendix", "The Perturbed Variation", "Policy Evaluation with Variance Related Risk Criteria in Markov Decision Processes", "Robust High Dimensional Sparse Regression and Matching Pursuit", "Online Learning for Time Series Prediction", "Online Learning for Loss Functions with Memory and Applications to Statistical Arbitrage", "A Primal Condition for Approachability with Partial Monitoring", "Efficiency Loss in a Network Resource Allocation Game: The Case of Elastic Supply", "Strategies for prediction under imperfect monitoring", "Algorithmic aspects of mean-variance optimization in Markov decision processes.", "Dynamics in tree formation games.", "A contract-based model for directed network formation.", "Regret minimization in repeated matrix games with variable stage duration.", "Approachability in repeated games: Computational aspects and a Stackelberg variant.", "Stochastic Chase Decoding of Reed-Solomon Codes.", "Stochastic decoding of LDPC codes.", "A State Action Frequency Approach to Throughput Maximization over Uncertain Wireless Channels.", "Percentile Optimization for Markov Decision Processes with Parameter Uncertainty.", "Optimization Under Probabilistic Envelope Constraints.", "Does an Efficient Calibrated Forecasting Strategy Exist?", "Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems.", "More Is Better: Large Scale Partially-supervised Sentiment Classication.", "Greedy Algorithms for Classification -- Consistency, Convergence Rates, and Adaptivity.", "Robust approachability and regret minimization in games with partial monitoring.", "Set-valued approachability and online learning with partial monitoring.", "A Geometric Approach to Multi-Criterion Reinforcement Learning.", "Preface.", "The Sample Complexity of Exploration in the Multi-Armed Bandit Problem.", "Online Learning with Sample Path Constraints.", "The Sample Complexity of Dictionary Learning.", "The Sample Complexity of Dictionary Learning.", "Robustness and Regularization of Support Vector Machines.", "Statistical Optimization in High Dimensions.", "Efficiency of Market-Based Resource Allocation among Many Participants.", "Bias and Variance Approximation in Value Function Estimates.", "On the Existence of Linear Weak Learners and Applications to Boosting.", "Online calibrated forecasts: Memory efficiency versus universality for learning in games.", "Robustness and generalization.", "Opportunistic Approachability and Generalized No-Regret Problems.", "Strategies for Prediction Under Imperfect Monitoring.", "The Empirical Bayes Envelope and Regret Minimization in Competitive Markov Decision Processes.", "A Geometric Proof of Calibration.", "On the Empirical State-Action Frequencies in Markov Decision Processes Under General Policies.", "A Distributional Interpretation of Robust Optimization.", "Distributionally Robust Markov Decision Processes.", "Markov Decision Processes with Arbitrary Reward Processes.", "Time Series Analysis Using Geometric Template Matching.", "Sparse Algorithms Are Not Stable: A No-Free-Lunch Theorem.", "Generating storylines from sensor data.", "On information propagation in mobile call networks.", "Network Formation: Bilateral Contracting and Myopic Dynamics.", "Design of \u2113", "Efficiency loss in a network resource allocation game: the case of elastic supply.", "A Kalman Filter Design Based on the Performance/Robustness Tradeoff.", "A Min-Sum Iterative Decoder Based on Pulsewidth Message Encoding.", "A Robust Learning Approach to Repeated Auctions With Monitoring and Entry Fees.", "Dithered Belief Propagation Decoding.", "Relaxed Half-Stochastic Belief Propagation.", "Stochastic Decoding of LDPC Codes over GF(q).", "An Inequality for Nearly Log-Concave Distributions With Applications to Learning.", "Robust regression and Lasso.", "Outlier-Robust PCA: The High-Dimensional Case.", "Efficient Bidding in Dynamic Grid Markets.", "High-Throughput Energy-Efficient LDPC Decoders Using Differential Binary Message Passing.", "The kernel recursive least-squares algorithm.", "Delayed Stochastic Decoding of LDPC Codes.", "Fully Parallel Stochastic LDPC Decoders.", "Majority-based tracking forecast memories for stochastic LDPC decoding.", "Relaxation dynamics in stochastic iterative decoders.", "Tracking Forecast Memories for Stochastic Decoding.", null]]